def build_model(hp):
    model = Sequential()

    # 1st LSTM Layer
    model.add(LSTM(
        units=hp.Int('lstm_units_1', min_value=32, max_value=128, step=32),  
        return_sequences=True, 
        input_shape=(SEQ_LENGTH, 1)
    ))
    model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.3, step=0.1)))
    model.add(BatchNormalization())

    # 2nd LSTM Layer
    model.add(LSTM(
        units=hp.Int('lstm_units_2', min_value=16, max_value=128, step=16),  
        return_sequences=True
    ))
    model.add(Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.3, step=0.1)))

    # 3rd LSTM Layer
    model.add(LSTM(
        units=hp.Int('lstm_units_3', min_value=16, max_value=128, step=16),  
        return_sequences=False
    ))

    # Tuned Dense Layer
    model.add(Dense(
        units=hp.Int('dense_units', min_value=8, max_value=64, step=8),  
        activation='relu'
    ))

    # Output Layer
    model.add(Dense(1))  # Regression output

    # Optimizer Tuning
    learning_rate = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')
    optimizer = Adam(learning_rate=learning_rate)

    # Compile model
    model.compile(
        optimizer=optimizer,
        loss=Huber(delta=hp.Float('huber_delta', 0.5, 1.5, step=0.1)),  
        metrics=['mae']
    )
    
    return model

